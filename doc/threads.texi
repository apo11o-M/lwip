@node Project 1--Threads
@chapter Project 1: Threads

In this assignment, we give you a minimally functional thread system.
Your job is to extend the functionality of this system to gain a
better understanding of synchronization problems.

You will be working primarily in the @file{threads} directory for
this assignment, with some work in the @file{devices} directory on the
side.  Compilation should be done in the @file{threads} directory.

Before you read the description of this project, you should read all of
the following sections: @ref{Introduction}, @ref{Coding Standards},
@ref{Debugging Tools}, and @ref{Development Tools}.  You should at least
skim the material from @ref{Pintos Loading} through @ref{Memory
Allocation}, especially @ref{Synchronization}.  To complete this project
you will also need to read @ref{Completely Fair Scheduler}.

@menu
* Project 1 Background::        
* Project 1 Requirements::      
* Project 1 Tests::
* Project 1 FAQ::               
@end menu

@node Project 1 Background
@section Background


@menu
* Understanding Threads::       
* Understanding CPUs::
* Project 1 Source Files::      
* Project 1 Synchronization::   
* Development Suggestions::     
@end menu

@node Understanding Threads
@subsection Understanding Threads

The first step is to read and understand the code for the initial thread
system.
Pintos already implements thread creation and thread completion,
a simple scheduler to switch between threads, and synchronization
primitives (semaphores, locks, condition variables, and optimization
barriers).

Some of this code might seem slightly mysterious.  If
you haven't already compiled and run the base system, as described in
the introduction (@pxref{Introduction}), you should do so now.  You
can read through parts of the source code to see what's going
on.  If you like, you can add calls to @func{printf} almost
anywhere, then recompile and run to see what happens and in what
order.  You can also run the kernel in a debugger and set breakpoints
at interesting spots, single-step through code and examine data, and
so on.

When a thread is created, you are creating a new context to be
scheduled.  You provide a function to be run in this context as an
argument to @func{thread_create}.  The first time the thread is
scheduled and runs, it starts from the beginning of that function
and executes in that context.  When the function returns, the thread
terminates.  Each thread, therefore, acts like a mini-program running
inside Pintos, with the function passed to @func{thread_create}
acting like @func{main}.

At any given time, exactly one thread runs on each CPU.
The remaining threads, if any, become inactive.  
The scheduler decides which thread to run next on a CPU.
(If no thread is ready to run at any given time, then the 
special ``idle'' thread, implemented in @func{idle}, runs.)
Synchronization primitives can force context switches when one
thread needs to wait for another thread to do something.

The mechanics of a context switch are
in @file{threads/switch.S}, which is 80@var{x}86
assembly code.  (You don't have to understand it.)  It saves the
state of the currently running thread and restores the state of the
thread we're switching to.

Using the GDB debugger, slowly trace through a context
switch to see what happens (@pxref{GDB}).  You can set a
breakpoint on @func{schedule} to start out, and then
single-step from there.@footnote{GDB might tell you that
@func{schedule} doesn't exist, which is arguably a GDB bug.
You can work around this by setting the breakpoint by filename and
line number, e.g.@: @code{break thread.c:@var{ln}} where @var{ln} is
the line number of the first declaration in @func{schedule}.}  Be sure
to keep track of each thread's address
and state, and what procedures are on the call stack for each thread.
You will notice that when one thread calls @func{switch_threads},
another thread starts running, and the first thing the new thread does
is to return from @func{switch_threads}.  You will understand the thread
system once you understand why and how the @func{switch_threads} that
gets called is different from the @func{switch_threads} that returns.
@xref{Thread Switching}, for more information.

@strong{Warning}: In Pintos, each thread is assigned a small,
fixed-size execution stack just under @w{4 kB} in size.  The kernel
tries to detect stack overflow, but it cannot do so perfectly.  You
may cause bizarre problems, such as mysterious kernel panics, if you
declare large data structures as non-static local variables,
e.g. @samp{int buf[1000];}.  Alternatives to stack allocation include
the page allocator and the block allocator (@pxref{Memory Allocation}).

@node Understanding CPUs
@subsection Understanding CPUs

In an operating system that supports multiple CPUs, such as this version
of Pintos, each CPU must be independently managed.  For instance, the
OS needs to track keep of which threads are currently assigned to
that CPU, and which thread is currently running on that CPU (or whether
that CPU's idle thread is running).

Per-CPU information is also used for interrupt management, as multiple
CPUs may each be handling interrupts.

@xref{Struct CPU}. for full details of how a CPU is represented in Pintos.

@node Project 1 Source Files
@subsection Source Files

Here is a brief overview of the files in the @file{threads}
directory.  You will not need to modify most of this code, but the
hope is that presenting this overview will give you a start on what
code to look at.

@table @file
@item loader.S
@itemx loader.h
The kernel loader.  Assembles to 512 bytes of code and data that the
PC BIOS loads into memory and which in turn finds the kernel on disk,
loads it into memory, and jumps to @func{start} in @file{start.S}.
@xref{Pintos Loader}, for details.  You should not need to look at
this code or modify it.

@item start.S
Does basic setup needed for memory protection and 32-bit
operation on 80@var{x}86 CPUs.  Unlike the loader, this code is
actually part of the kernel.  @xref{Low-Level Kernel Initialization},
for details. Jumps to @func{main}

@item startother.S
Similar to start.S, but whereas start.S is executed by the Bootstrap
processor (@acronym{BSP}), startother.S is executed by application 
processors (@acronym{AP}). Jumps to @func{mpenter}

@item kernel.lds.S
The linker script used to link the kernel.  Sets the load address of
the kernel and arranges for @file{start.S} to be near the beginning
of the kernel image.  @xref{Pintos Loader}, for details. Again, you
should not need to look at this code
or modify it, but it's here in case you're curious.

@item init.c
@itemx init.h
Kernel initialization, including @func{main}, the kernel's ``main
program.''  You should look over @func{main} at least to see what
gets initialized.  You might want to add your own initialization code
here.  @xref{High-Level Kernel Initialization}, for details.

@item thread.c
@itemx thread.h
Basic thread support.  Much of your work will take place in these files.
@file{thread.h} defines @struct{thread}, which you are likely to modify
in all four projects.  See @ref{struct thread} and @ref{Threads} for
more information.

@item switch.S
@itemx switch.h
Assembly language routine for switching threads.  Already discussed
above.  @xref{Thread Functions}, for more information.

@item palloc.c
@itemx palloc.h
Page allocator, which hands out system memory in multiples of 4 kB
pages.  @xref{Page Allocator}, for more information.

@item malloc.c
@itemx malloc.h
A simple implementation of @func{malloc} and @func{free} for
the kernel.  @xref{Block Allocator}, for more information.

@item mp.c
@item mp.h
Parses the MP Configuration Table left by the BIOS. Used to discover how many cores are present on the processor.

@item interrupt.c
@itemx interrupt.h
Basic interrupt handling and functions for turning interrupts on and
off.  @xref{Interrupt Handling}, for more information.

@item intr-stubs.S
@itemx intr-stubs.h
Assembly code for low-level interrupt handling.  @xref{Interrupt
Infrastructure}, for more information.

@item spinlock.c
@itemx spinlock.h
Implementation of spinlocks.  Spinlocks are low-level synchronization
primitives.  Some parts of the kernel use them directly, but because of
their restrictions, usually higher-level synchronization primitives
such as locks or semaphores are being used.
@xref{Synchronization}, for more information.

@item synch.c
@itemx synch.h
Basic synchronization primitives: semaphores, locks, condition
variables, and optimization barriers.  You will need to use these for
synchronization in all
four projects.  @xref{Synchronization}, for more information.

@item gdt.c
@itemx gdt.h
The 80@var{x}86 is a segmented architecture.  The Global Descriptor
Table (GDT) is a table that describes the segments in use.  These
files set up the GDT.  You should not need to modify these
files for any of the projects.  You can read the code if
you're interested in how the GDT works.

@item tss.c
@itemx tss.h
The Task-State Segment (TSS) is used for 80@var{x}86 architectural
task switching.  Pintos uses the TSS only for switching stacks when a
user process enters an interrupt handler, as does Linux.  You
should not need to modify these files for any of the projects.
You can read the code if you're interested in how the TSS
works.

@item io.h
Functions for I/O port access.  This is mostly used by source code in
the @file{devices} directory that you won't have to touch.

@item vaddr.h
@itemx pte.h
Functions and macros for working with virtual addresses and page table
entries.  These will be more important to you in project 3.  For now,
you can ignore them.

@item flags.h
Macros that define a few bits in the 80@var{x}86 ``flags'' register.
Probably of no interest.  See @bibref{IA32-v1}, section 3.4.3, ``EFLAGS
Register,'' for more information.
@end table

@menu
* devices code::                
* lib files::                   
@end menu

@node devices code
@subsubsection @file{devices} code

The basic threaded kernel also includes these files in the
@file{devices} directory:

@table @file
@item timer.c
@itemx timer.h
System timer that ticks, by default, 1000 times per second.  You will
modify this code in this project.

@item vga.c
@itemx vga.h
VGA display driver.  Responsible for writing text to the screen.
You should have no need to look at this code.  @func{printf}
calls into the VGA display driver for you, so there's little reason to
call this code yourself.

@item serial.c
@itemx serial.h
Serial port driver.  Again, @func{printf} calls this code for you,
so you don't need to do so yourself.
It handles serial input by passing it to the input layer (see below).

@item block.c
@itemx block.h
An abstraction layer for @dfn{block devices}, that is, random-access,
disk-like devices that are organized as arrays of fixed-size blocks.
Out of the box, Pintos supports two types of block devices: IDE disks
and partitions.  Block devices, regardless of type, won't actually be
used until project 2.

@item ide.c
@itemx ide.h
Supports reading and writing sectors on up to 4 IDE disks.

@item partition.c
@itemx partition.h
Understands the structure of partitions on disks, allowing a single
disk to be carved up into multiple regions (partitions) for
independent use.

@item kbd.c
@itemx kbd.h
Keyboard driver.  Handles keystrokes passing them to the input layer
(see below).

@item input.c
@itemx input.h
Input layer.  Queues input characters passed along by the keyboard or
serial drivers.

@item intq.c
@itemx intq.h
Interrupt queue, for managing a circular queue that both kernel
threads and interrupt handlers want to access.  Used by the keyboard
and serial drivers.

@item rtc.c
@itemx rtc.h
Real-time clock driver, to enable the kernel to determine the current
date and time.  By default, this is only used by @file{thread/init.c}
to choose an initial seed for the random number generator.

@item speaker.c
@itemx speaker.h
Driver that can produce tones on the PC speaker.

@item pit.c
@itemx pit.h
Code to configure the 8254 Programmable Interrupt Timer.  This code is
used by both @file{devices/timer.c} and @file{devices/speaker.c}
because each device uses one of the PIT's output channel.

@item ioapic.c
@itemx ioapic.h
Configures the I/O Advanced Programmable Interrupt Controller. The function @func{ioapicenable} is called by several device drivers during initialization. All I/O drivers in PintOS routes I/O interrupts to CPU0. 

@item lapic.c
@itemx lapic.h
Configures the Local Advanced Programmable Interrupt Controller, which is built into every CPU. It provides timer interrupts for each CPU and generates inter-processor interrupts (@acronym{IPI}) to other CPUs.  

@end table

@node lib files
@subsubsection @file{lib} files

Finally, @file{lib} and @file{lib/kernel} contain useful library
routines.  (@file{lib/user} will be used by user programs, starting in
project 2, but it is not part of the kernel.)  Here's a few more
details:

@table @file
@item ctype.h
@itemx inttypes.h
@itemx limits.h
@itemx stdarg.h
@itemx stdbool.h
@itemx stddef.h
@itemx stdint.h
@itemx stdio.c
@itemx stdio.h
@itemx stdlib.c
@itemx stdlib.h
@itemx string.c
@itemx string.h
A subset of the standard C library.  @xref{C99}, for
information
on a few recently introduced pieces of the C library that you might
not have encountered before.  @xref{Unsafe String Functions}, for
information on what's been intentionally left out for safety.

@item debug.c
@itemx debug.h
Functions and macros to aid debugging.  @xref{Debugging Tools}, for
more information.

@item random.c
@itemx random.h
Pseudo-random number generator.  The actual sequence of random values
will not vary from one Pintos run to another, unless you do one of
three things: specify a new random seed value on the @option{-rs}
kernel command-line option on each run, or use a simulator other than
Bochs, or specify the @option{-r} option to @command{pintos}.

@item atomic-ops.c
@itemx atomic-ops.h
Atomic instructions

@item round.h
Macros for rounding.

@item syscall-nr.h
System call numbers.  Not used until project 2.

@item kernel/list.c
@itemx kernel/list.h
Doubly linked list implementation.  Used all over the Pintos code, and
you'll probably want to use it a few places yourself in project 1.

@item kernel/bitmap.c
@itemx kernel/bitmap.h
Bitmap implementation.  You can use this in your code if you like, but
you probably won't have any need for it in project 1.

@item kernel/hash.c
@itemx kernel/hash.h
Hash table implementation.  Likely to come in handy for project 3.

@item kernel/console.c
@itemx kernel/console.h
@item kernel/stdio.h
Implements @func{printf} and a few other functions.
@end table

@node Project 1 Synchronization
@subsection Synchronization

Proper synchronization is an important part of the solutions to these
problems.  
Read the tour section on
synchronization (@pxref{Synchronization}) or the comments in
@file{threads/synch.c} if you're unsure what synchronization primitives
may be used in what situations. In particular, it is important to know 
when a spinlock should be acquired as opposed to a lock (and vice versa)

When interrupts are off, take care to do so for the least amount
of code possible, or you can end up losing important things such as
timer ticks or input events.  Turning off interrupts also increases the
interrupt handling latency, which can make a machine feel sluggish if
taken too far. Remember that interrupts are off for the entirety of
the time that a spinlock is held.

The synchronization primitives themselves in @file{synch.c} are
implemented by disabling interrupts.

Disabling interrupts can be useful for debugging, if you want to make
sure that a section of code is not interrupted.  You should remove
debugging code before turning in your project.  (Don't just comment it
out, because that can make the code difficult to read.)

There should be no busy waiting in your submission.  A tight loop that
calls @func{thread_yield} is one form of busy waiting.

@node Development Suggestions
@subsection Development Suggestions

In the past, many groups divided the assignment into pieces, then each
group member worked on his or her piece until just before the
deadline, at which time the group reconvened to combine their code and
submit.  @strong{This is a bad idea.  We do not recommend this
approach.}  Groups that do this often find that two changes conflict
with each other, requiring lots of last-minute debugging.  Some groups
who have done this have turned in code that did not even compile or
boot, much less pass any tests.

@localcvspolicy{}

You should expect to run into bugs that you simply don't understand
while working on this and subsequent projects.  When you do,
reread the appendix on debugging tools, which is filled with
useful debugging tips that should help you to get back up to speed
(@pxref{Debugging Tools}).  Be sure to read the section on backtraces
(@pxref{Backtraces}), which will help you to get the most out of every
kernel panic or assertion failure.

@node Project 1 Requirements
@section Requirements

@menu
* Project 1 Design Document::   
* Alarm Clock::                 
* Advanced Scheduler::          
* Load Balancer::
@end menu

@node Project 1 Design Document
@subsection Design Document

Before you turn in your project, you must copy @uref{threads.tmpl, , the
project 1 design document template} into your source tree under the name
@file{pintos/src/threads/DESIGNDOC} and fill it in.  We recommend that
you read the design document template before you start working on the
project.  @xref{Project Documentation}, for a sample design document
that goes along with a fictitious project.

@node Alarm Clock
@subsection Alarm Clock

Reimplement @func{timer_sleep}, defined in @file{devices/timer.c}.
Although a working implementation is provided, it ``busy waits,'' that
is, it spins in a loop checking the current time and calling
@func{thread_yield} until enough time has gone by.  Reimplement it to
avoid busy waiting.

@deftypefun void timer_sleep (int64_t @var{ticks})
Suspends execution of the calling thread until time has advanced by at
least @w{@var{x} timer ticks}.  Unless the system is otherwise idle, the
thread need not wake up after exactly @var{x} ticks.  Just put it on
the ready queue after they have waited for the right amount of time.

@func{timer_sleep} is useful for threads that operate in real-time,
e.g.@: for blinking the cursor once per second.

The argument to @func{timer_sleep} is expressed in timer ticks, not in
milliseconds or any another unit.  There are @code{TIMER_FREQ} timer
ticks per second, where @code{TIMER_FREQ} is a macro defined in
@code{devices/timer.h}.  
@end deftypefun

Separate functions @func{timer_msleep}, @func{timer_usleep}, and
@func{timer_nsleep} do exist for sleeping a specific number of
milliseconds, microseconds, or nanoseconds, respectively, but these will
call @func{timer_sleep} automatically when necessary.  You do not need
to modify them.

@c If your delays seem too short or too long, reread the explanation of the
@c @option{-r} option to @command{pintos} (@pxref{Debugging versus
@c Testing}).

The alarm clock implementation is not needed for later projects,
although it could be useful for project 4.

@node Advanced Scheduler
@subsection Advanced Scheduler

For this part of the project, you will be working primarily in @file{threads/scheduler.c}.

The goal of a general-purpose scheduler is to balance threads' different
scheduling needs. Threads that perform a lot of I/O require a fast
response time to keep input and output devices busy, but need little
CPU time. On the other hand, compute-bound threads need to receive a
lot of CPU time to finish their work, but have no requirement for fast
response time. Other threads lie somewhere in between, with periods of
I/O punctuated by periods of computation, and thus have requirements
that vary over time. A well-designed scheduler can often accommodate
threads with all these requirements simultaneously.

In addition, schedulers also have the following general goals:@*
@enumerate
@item
Being "fair" to each thread. That is, giving each thread an equal amount of CPU time.

@item
Minimizing the service error, defined as the difference between the amount of CPU time a thread should have received versus the amount of CPU time a thread actually did receive.

@item
Minimizing scheduling overhead.

@end enumerate

Often, the latter two goals conflict with each other.

Implement an advanced scheduler similar to the
@acronym{CFS} scheduler used by Linux.
@xref{Completely Fair Scheduler}, for detailed requirements.

Many scheduling decisions in @acronym{CFS} depends on how long a thread has run
in realtime. To calculate this, you should use @code{timer_gettime ()}.

@deftypefun uint64_t timer_gettime (void)
Returns the amount of nanoseconds that has passed since the OS booted.
@end deftypefun

The advanced scheduler is not used in any later project.

@node Load Balancer
@subsection Load Balancer

Multiprocessor scheduling is one of many difficulties that arose with the
arrival of multicore technology. How can an operating system keep all cores
busy?

One of the simplist ways to do this is to keep the threads in a global queue
that is shared by all CPUs. An advantage to this approach is that it ensures
that no CPU is idle while threads are ready to run (but are not currently
running). However, global queue has two main weaknesses.

The first weakness is lack of
scability. The global queue must be locked while choosing the next job to run.
Locking greatly reduces performance as the number of CPUs grow. Each CPU will
spend more and more time contenting for the global queue lock and less time
actually running threads.

The second weakness is cache affinity. A thread builds up a fair amount of
state in the cache and TLB associated with its running CPU. It is advantageous
to run it on the same CPU each time, as it will run faster than if it ran on
a different CPU where its memory is far less likely to be stored in the CPU cache.
A global queue makes preserving cache affinity far less likely, since threads are
equally likely to be chosen by any CPU.

Because of the weaknesses described above, many operating systems, including Pintos,
uses per-CPU queues. Each CPU cycles through the threads on their own queue, 
independent of other CPUs, thereby avoiding the scability and cache affinity problems
found in the global queue approach. 

However, the multiqueue approach has a problem not seen in the single queue approach:
load imbalance. If CPU0 has one threads A, and CPU1 has two threads B and C, then A has
exclusive access to CPU0, while B and C take turns being scheduled on CPU1. A then
is given twice as much runtime as B and C. Even worse, imagine if thread A finishes. 
Then CPU0 is idle, while CPU1 is cycling through B and C! Wouldn't it be great if 
at this point C can be moved to CPU0, so both threads get exclusive access to the CPU? 

@b{Implement load balancing in Pintos.} 

In Pintos, when a thread is created, it is assigned a CPU in a round-robin fashion and
added to its local queue.
Please @b{DO NOT} change this, as it is an assumption made by the load balance test. 
This policy, although simple, does not guarantee that CPUs will be balanced. Although
CPUs are assigned equal number of threads, the threads on one CPU may finish faster
than the other, causing the former to become idle.

A good load balancing strategy achieves the following:
@enumerate
@item
No CPU is idle while another CPU has threads waiting in the ready queue. This 
is the primary goal

@item
Each CPU should be equally loaded.

@item
Wherever possible, minimize the migration of threads, since migrating a thread
to a different CPU means it will run with a cold cache the next time it is 
scheduled.
@end enumerate

Any CPU assignment policy, no matter how sophisticated, is not by itself enough
to ensure that the first goal is met. Therefore, any acceptable load balancing 
mechanism needs to move threads around. 

Create a function called @func{load_balance}.

@deftypefun void load_balance (void)
Pull threads from another CPU's local queue and add
it to the current CPU's local queue.
@xref{Load Balancing}, to see the detailed requirements.
@end deftypefun

It is up to you how often to load balance, but at the very least, load balancing 
must be performed inside the idle loop.

@node Project 1 Tests
@section Test Overview

The CFS tests do not actually create or schedule any real threads.
Instead, it runs a scheduler simulator that simulates scheduling threads
under your scheduler. The simulator does everything a real scheduler does,
with one
crucial difference: it does not actually context switch threads! All it
cares is that the correct thread is selected to run at the correct time,
it doesn't bother actually running the threads. The goal
is to be able to create a wide variety of scheduling scenarios and see 
if your scheduler makes the correct decisions. 
See @file{tests/threads/schedtest.c} and @file{tests/threads/simulator.c}.

The set up explained below. It is implemented in 
@func{setUp} and @func{tearDown}, defined in @file{tests/threads/schedtest.c},
so it may be useful to have that up in a separate window while reading.

The simulator sets up a "fake CPU" that doesn't represent any
CPU on the hardware, but rather a virtual environment where the simulator 
can create threads, execute timer interrupts, etc, without affecting the 
system. During setup, @func{change_cpu} is called so that the CPU local
variable @code{cpu} points to the fake CPU. After that, all OS events are applied
to the fake CPU. The real CPU is restored at the end of the test. 

During testing, interrupts are disabled, so now real timer interrupts
will arrive. Timer interrupts are simulated
by setting the system time via @func{timer_settime} and then executing
@func{driver_interrupt_tick}, which in turn invokes @func{driver_tick}.
These functions are almost identical to @func{timer_interrupt} in 
@file{devices/timer.c} and @func{thread_tick} in @file{thread.c} respectively.

At the beginning of each test, the system time is set to 0, so any time spent
prior to the test does not affect the test. Each test defines a set of OS events
that arrive after a certain amount of time. Each OS event is a scheduling event
that will invoke your scheduler. At the end of each event, the test checks that the
thread that your scheduler would run at the end of the event is the correct one. The
real time is restored at the end of the test.

The alarm, child-run, and balance tests do not run the
simulator, but rather schedule real threads doing real work under your 
scheduler. As a consequence, those tests take significantly longer.

@node Project 1 FAQ
@section FAQ

@table @b
@item How much code will I need to write?

Here's a summary of our reference solution, produced by the
@command{diffstat} program.  The final row gives total lines inserted
and deleted; a changed line counts as both an insertion and a deletion.

The reference solution represents just one possible solution.  Many
other solutions are also possible and many of those differ greatly from
the reference solution.  Some excellent solutions may not modify all the
files modified by the reference solution, and some may modify files not
modified by the reference solution.

@verbatim
 TODO
@end verbatim

@item How do I update the @file{Makefile}s when I add a new source file?

@anchor{Adding Source Files}
To add a @file{.c} file, edit the top-level @file{Makefile.build}.
Add the new file to variable @samp{@var{dir}_SRC}, where
@var{dir} is the directory where you added the file.  For this
project, that means you should add it to @code{threads_SRC} or
@code{devices_SRC}.  Then run @code{make}.  If your new file
doesn't get
compiled, run @code{make clean} and then try again.

When you modify the top-level @file{Makefile.build} and re-run
@command{make}, the modified
version should be automatically copied to
@file{threads/build/Makefile}.  The converse is
not true, so any changes will be lost the next time you run @code{make
clean} from the @file{threads} directory.  Unless your changes are
truly temporary, you should prefer to edit @file{Makefile.build}.

A new @file{.h} file does not require editing the @file{Makefile}s.

@item What does @code{warning: no previous prototype for `@var{func}'} mean?

It means that you defined a non-@code{static} function without
preceding it by a prototype.  Because non-@code{static} functions are
intended for use by other @file{.c} files, for safety they should be
prototyped in a header file included before their definition.  To fix
the problem, add a prototype in a header file that you include, or, if
the function isn't actually used by other @file{.c} files, make it
@code{static}.

@item What is the interval between timer interrupts?

Timer interrupts occur @code{TIMER_FREQ} times per second. 
The default is 1000Hz. It is set in @file{devices/timer.h}.
We do not recommend changing it, since it may cause some of the
tests to fail.

@item How long is a time slice?

There are @code{TIME_SLICE} ticks per time slice.  This macro is
declared in @file{threads/thread.c}.  The default is 4 ticks.
However, in Project 1 you will change the scheduler to dynamically
calculate an ideal timeslice, under the unit of nanoseconds rather than
ticks.

@item How do I run the tests?

@xref{Testing}.

@item Why do I get a test failure in @func{pass}?

@anchor{The pass function fails}
You are probably looking at a backtrace that looks something like this:

@example
0xc0108810: debug_panic (lib/kernel/debug.c:32)
0xc010a99f: pass (tests/threads/tests.c:93)
0xc010bdd3: test_mlfqs_load_1 (...threads/mlfqs-load-1.c:33)
0xc010a8cf: run_test (tests/threads/tests.c:51)
0xc0100452: run_task (threads/init.c:283)
0xc0100536: run_actions (threads/init.c:333)
0xc01000bb: main (threads/init.c:137)
@end example

This is just confusing output from the @command{backtrace} program.  It
does not actually mean that @func{pass} called @func{debug_panic}.  In
fact, @func{fail} called @func{debug_panic} (via the @func{PANIC}
macro).  GCC knows that @func{debug_panic} does not return, because it
is declared @code{NO_RETURN} (@pxref{Function and Parameter
Attributes}), so it doesn't include any code in @func{fail} to take
control when @func{debug_panic} returns.  This means that the return
address on the stack looks like it is at the beginning of the function
that happens to follow @func{fail} in memory, which in this case happens
to be @func{pass}.

@xref{Backtraces}, for more information.

@item How do runqueue spinlocks get released in the new thread following @func{schedule}?

Every path into @func{schedule} acquires a runqueue spinlock.  They eventually
get released by the next thread to be scheduled. This is the special case
where the thread that acquired a spinlock is not necessarily the thread
that releases it. Consider the
possibilities: the new thread is running in @func{switch_thread} (but
see below), which is called by @func{schedule}, which is called by one
of a few possible functions:

@itemize @bullet
@item
@func{thread_exit}, but we'll never switch back into such a thread, so
it's uninteresting.

@item
@func{thread_yield}, which immediately releases the runqueue lock upon
return from @func{schedule}.

@item
@func{thread_block}, which immediately releases the runqueue lock upon
return from @func{schedule}.

There is a special case when a newly created thread runs for the first
time.  Such a thread calls releases the runqueue lock as the first action in
@func{kernel_thread}, which is at the bottom of the call stack for every
kernel thread but the first.

@end itemize
@end table

@menu
* Alarm Clock FAQ::             
* Advanced Scheduler FAQ::      
* Load Balancer FAQ::
@end menu

@node Alarm Clock FAQ
@subsection Alarm Clock FAQ

@table @b
@item Do I need to account for timer values overflowing?

Don't worry about the possibility of timer values overflowing.  Timer
values are expressed as signed 64-bit numbers, which at 100 ticks per
second should be good for almost 2,924,712,087 years.  By then, we
expect Pintos to have been phased out of the @value{coursenumber} curriculum.
@end table

@node Advanced Scheduler FAQ
@subsection Advanced Scheduler FAQ

@table @b
@item Some scheduler tests fail and I don't understand why.  Help!

If your implementation mysteriously fails some of the advanced
scheduler tests, try the following:

@itemize
@item
Read the source files for the tests that you're failing, to make sure
that you understand what's going on.  Each one has a comment at the
top that explains its purpose and expected results.

@item
For the driver-related tests, make sure you understand how the scheduling
driver works. Then, check which assertion you are failing. The tests call
your scheduler multiple times under different events, and assert that the
correct thread is running. See which one the test expects, and why your 
code is not selecting the right thread to run. Beware of off-by-one errors.
@end itemize

@item I don't understand how the scheduling driver works/how tests are run

@xref{Project 1 Tests}.
@end table

@node Load Balancer FAQ
@subsection Load Balancer FAQ

@table @b
@item The synch tests take forever!

Race conditions are, by nature, not guaranteed to occur. The goal of the test
is to fail with high probability if race conditions are present. We designed them
by identifying the critical sections that you will have to protect with synchronization,
and entering the critical sections enough times that it is likely two threads will try
to enter at the same time, either because a timer interrupt preempted the first thread or
because they are running on different CPUs. The critical sections are rather small, so
the tests have to be repeated, which leads to high execution time.

You can try speeding the tests up by enabling KVM if it is available to you, but it is not guaranteed
to help because the speedup provided by KVM may make the already-small critical sections even
smaller, meaning it may not produce a failure even if race conditions are present.
Remember that timer interrupts still come at the same time intervals, despite the code
running a lot faster. Instead we recommend writing a script to run the tests many times (and in parallel,
by using tmux for example) and saving output in case of a kernel panic.
@end table

